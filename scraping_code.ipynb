{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e82b761",
   "metadata": {},
   "source": [
    "## project outlines\n",
    "\n",
    "- In this project we are going to scrape 'http://github.com/topics'.\n",
    "- we are going to scrape github's entire list of topics\n",
    "- For each topic we are going to get a list of upto 7 pages usernames,reponames and their stars\n",
    "- This project is divided into two sections\n",
    "- section 1 scrapes the entire topics and creates a dataframe consisting of topicname,description and url\n",
    "- section 2 scrapes the contents of each topic by taking topic url from the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991da68",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "\n",
    "- we are scraping a list of topics of upto 5 pages\n",
    "- we are creating three arrays named topic_titles,topic_desc(for descriptions) and topic_url(for urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcb9e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65cd6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-10\n",
    "#takes lists of titles,desc,urls and returns a dataframe for the same\n",
    "def convert_to_dataframe(topic_titles,topic_desc,\n",
    "                            topic_url):\n",
    "    \n",
    "    df_dict = {\n",
    "        'title':topic_titles,\n",
    "        'desc': topic_desc,\n",
    "        'url': topic_url\n",
    "    }\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43a4cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-9\n",
    "#Takes in tags containing url and a list, extracts url from tags and returns list of urls of topics\n",
    "def extract_url(url_tags,\n",
    "                topic_url):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for tp_url in url_tags:\n",
    "        topic_url.append('http://github.com'+tp_url['href'])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6420ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions scrapes description from the topic pages\n",
    "'''\n",
    "It takes p tags in whic descripion is present and titles_desc list as input,Extracts description\n",
    "and appends to list.\n",
    "'''\n",
    "#Block-8\n",
    "def extract_description(desc_tags,\n",
    "                       topic_desc):\n",
    "    \n",
    "        for tag in desc_tags:\n",
    "            topic_desc.append(tag.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22c599d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions scrapes titles from the topic pages\n",
    "#It takes tags where topic title present and titles list as input,Extracts titles and appends to list.\n",
    "\n",
    "#Block-7\n",
    "def extract_titles(title_tags,\n",
    "                   topic_titles):\n",
    "    \n",
    "        for tag in title_tags:\n",
    "            topic_titles.append(tag.text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e2cd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-6\n",
    "#A function, which consists of a bunch of sub functions.\n",
    "\n",
    "def extraction_of_contents(topic_title_tags,topic_titles,\n",
    "                          topic_disc_tags,topic_desc,\n",
    "                          topic_url_tags,topic_url):\n",
    "    \n",
    "    \n",
    "    extract_titles(topic_title_tags,topic_titles)\n",
    "    extract_description(topic_disc_tags,topic_desc)\n",
    "    extract_url(topic_url_tags,topic_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16f10b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-5\n",
    "#This function takes a parsed html document and returns tags in a list which consists information in them.\n",
    "def extract_url_tags(doc):\n",
    "    \n",
    "    tags = doc.find_all('a',{'class':'no-underline flex-grow-0'})\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7e23498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-4\n",
    "#This function takes a parsed html document and returns tags in a list which consists information in them.\n",
    "def extract_desc_tags(doc):\n",
    "    \n",
    "    tags = doc.find_all('p',{'class':'f5 color-fg-muted mb-0 mt-1'})\n",
    "    return tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24d53c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-3\n",
    "#This function takes a parsed html document and returns tags in a list which consists information in them.\n",
    "def extract_title_tags(doc):\n",
    "    \n",
    "    tags = doc.find_all('p',{'class':'f3 lh-condensed mb-0 mt-1 Link--primary'})\n",
    "    return tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5331f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLock-2\n",
    "# takes in url,and returns a parsed html document\n",
    "def page_contents(url):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    page_content = response.text\n",
    "    doc = BeautifulSoup(page_content,'html.parser')\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a79364f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block-1\n",
    "def scrape_topics_content():\n",
    "    \n",
    "    topic_titles = []\n",
    "    topic_desc = []\n",
    "    topic_url = []\n",
    "    for i in range(1,5):\n",
    "    \n",
    "        url = 'https://github.com/topics?page='+str(i)\n",
    "        doc = page_contents(url)\n",
    "    \n",
    "        topic_title_tags = extract_title_tags(doc)\n",
    "        topic_disc_tags = extract_desc_tags(doc)\n",
    "        topic_url_tags =extract_url_tags(doc) \n",
    "        \n",
    "        extraction_of_contents(topic_title_tags,topic_titles,\n",
    "                              topic_disc_tags,topic_desc,\n",
    "                              topic_url_tags,topic_url)\n",
    "    \n",
    "            \n",
    "    df = convert_to_dataframe(topic_titles,topic_desc,topic_url)\n",
    "    df.to_csv('github_topics.csv',index = None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrape_topics_content()\n",
    "for i,j in df.iterrows():\n",
    "    start_extraction(j[2],j[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b71d1",
   "metadata": {},
   "source": [
    "# Part-2 Scrapes Each Topic's webpages upto 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in lists of usernames,reponames and stars and returns a data frame\n",
    "def convert_to_DataFrame(user_names,repo_names,\n",
    "                        stars):\n",
    "    \n",
    "    df_repo_dict = {\n",
    "        'repo_user_name' : user_names,\n",
    "        'repo_name' : repo_names,\n",
    "        'stars' : stars\n",
    "    }\n",
    "    df = pd.DataFrame(df_repo_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-7\n",
    "#Extracts stars from star tags and returns in int type\n",
    "def extract_stars_count(star):\n",
    "    \n",
    "    if star[-1] == 'k':\n",
    "        return int(float(star[:-1])*1000)\n",
    "    return int(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-6\n",
    "#Extracts username and reponame from repo_tags and returns as a tuple\n",
    "def extract_user_repo_names(repo_tags):\n",
    "    \n",
    "    user_name = repo_tags[0].text.strip()\n",
    "    repo_name = repo_tags[1].text.strip()\n",
    "    \n",
    "    return user_name,repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-5\n",
    "def extract_repo_info(repo_tags,repo_star_tags,\n",
    "                      user_names,repo_names,\n",
    "                      stars):\n",
    "    \n",
    "    \n",
    "    for i in range(len(repo_tags)):\n",
    "        \n",
    "        repo_username_tags = repo_tags[i].find_all('a')\n",
    "        star_count = extract_stars_count(repo_star_tags[i].text.strip())\n",
    "        user_name,repo_name = extract_user_repo_names(repo_username_tags)\n",
    "        \n",
    "        user_names.append(user_name)\n",
    "        repo_names.append(repo_name)\n",
    "        stars.append(star_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-4\n",
    "#takes a parsed document and returns list of tags which contains star tags\n",
    "def extract_star_tags(repo_contents):\n",
    "    \n",
    "    repo_star_tags = repo_contents.find_all('span',{'class':'Counter js-social-count'})\n",
    "    return repo_star_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-3\n",
    "#takes a parsed document and returns repo tags which contains usernames and repo names\n",
    "def extract_repo_tags(repo_contents):\n",
    "    \n",
    "        h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "        repo_tags = repo_contents.find_all('h3',{'class':h3_selection_class})\n",
    "        return repo_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f423fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2,Block-2\n",
    "#takes a url and returns a parsed document\n",
    "def repo_doc(url):\n",
    "    \n",
    "    response = requests.get(url+'?page=',i)\n",
    "    repo_page = response.text\n",
    "    repo_contents = BeautifulSoup(repo_page,'html.parser')\n",
    "    return repo_contents\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage-2 Block-1\n",
    "#A main function of stage-2\n",
    "def start_extraction(url,title):\n",
    "    user_names = []\n",
    "    repo_names = []\n",
    "    stars = []\n",
    "    for i in range(1,5):\n",
    "        \n",
    "        url = url + '?page' +str(i)\n",
    "        repo_contents = repo_doc(url)\n",
    "        \n",
    "        repo_tags = extract_repo_tags(repo_contents)\n",
    "        star_tags = extract_star_tags(repo_contents)\n",
    "\n",
    "        extract_repo_info(repo_tags,star_tags,\n",
    "                          user_names,repo_names,\n",
    "                          stars)\n",
    "        \n",
    "    print('Extracting for',title)\n",
    "    df = convert_to_DataFrame(user_names,repo_names,\n",
    "                           stars)\n",
    "    \n",
    "    df.to_csv(title+'.csv',index = None)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5743f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c81610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f557a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74ce07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
